{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3c3133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from code_assistant import CodeAssistant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e16e88",
   "metadata": {},
   "source": [
    "### Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d0824da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Ollama server with model: codellama:7b\n",
      "Assistant is ready to use!\n"
     ]
    }
   ],
   "source": [
    "assistant = CodeAssistant(model=\"codellama:7b\")\n",
    "print(\"Assistant is ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34c371",
   "metadata": {},
   "source": [
    "### Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "525c0de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Here is an example of how you can write a \"Hello, World!\" program in Python:\n",
      "  \n",
      "    def hello_world():\n",
      "        print(\"Hello, world!\")\n",
      "\n",
      "This code defines a function called `hello_world` that prints the string \"Hello, world!\" to the console when it is called. You can call this function by typing its name and parentheses, like this:\n",
      "\n",
      "    hello_world()\n",
      "\n",
      "When you run this program, it should print the string \"Hello, world!\" to the console.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a Hello World python function.\n",
    "\"\"\"\n",
    "\n",
    "completion = assistant.complete(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb8a0c8",
   "metadata": {},
   "source": [
    "### Multi Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create assistants with different models\n",
    "assistant1 = CodeAssistant(model=\"codellama:7b\")\n",
    "assistant2 = CodeAssistant(model=\"stable-code:3b\")\n",
    "assistant3 = CodeAssistant(model=\"deepseek-coder:6.7b\")\n",
    "\n",
    "# Compare results on the same prompt\n",
    "prompt = \"def binary_search(arr, target):\"\n",
    "\n",
    "print(\"=== CodeLlama 7B ===\")\n",
    "print(assistant1.complete(prompt))\n",
    "\n",
    "print(\"\\n=== StableCode 3B ===\")\n",
    "print(assistant2.complete(prompt))\n",
    "\n",
    "print(\"\\n=== DeepSeek Coder 6.7B ===\")\n",
    "print(assistant3.complete(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
